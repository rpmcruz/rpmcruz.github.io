---
layout: post
title: Tutorial on Generative Adversarial Networks
category: machine learning
---

{% raw  %}
Recently, I have come to use GANs during my research on data augmentation and class imbalance. I have heard of GANs before, but never used them. It was a somehow steep learning curve, because results were not as good as I would like and there was so much research that I didn't know where to head to. This tutorial is my attempt at distilling and making sense of this research area.

I am going to use TensorFlow in combination with Keras for this tutorial. Make sure you load these packages before running any of the code.

```python
from tensorflow.keras import models, layers, datasets, optimizers, backend, utils
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
```

## The origin

In **2014,** Goodfellow created the concept of a generator and a discriminator fighting each other, producing better and better images.

In this work, a **Generator** $$G$$ produces images $$\hat X$$ when given noise $$z$$.

$$z \rightarrow G \rightarrow \hat X$$

On the other hand, a **Discriminator** $$D$$ is trained to distinguish between these fake images and the real images $$X$$ from the dataset.

$$\hat X \rightarrow D \rightarrow 0$$
$$X \rightarrow D \rightarrow 1$$

These two models are playing the minimax game:

$$\min_G\max_D\mathbb E_{\mathbf x\sim p_\text{data}(\mathbf x)}[\log D(\mathbf x)] + \mathbb E_{\mathbf z\sim p_{\mathbf z(\mathbf z)}}[\log (1-D(G(\mathbf z)))].$$

<img src="/img/2019-05/gan.png" width="970" height="423">

* Goodfellow, Ian, et al. "[Generative adversarial nets.](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)" Advances in neural information processing systems. 2014.

We are going to use the MNIST dataset, a popular dataset which was also used in the aforementioned paper. These are 60,000 grayscale small 28x28 images of hand-written digits.

```python
(Xtr, Ytr), (Xts, Yts) = datasets.mnist.load_data()

# normalization: [0, 255] => [-1, 1]
Xtr = (Xtr/127.5 - 1).astype(np.float32)[:, :, :, np.newaxis]
Xts = (Xts/127.5 - 1).astype(np.float32)[:, :, :, np.newaxis]

# one-hot encoding (e.g. class 2 => [0, 0, 1, 0, 0, 0, 0])
Ytr = utils.to_categorical(Ytr)
Yts = utils.to_categorical(Yts)
```

Draw the dataset:

```python
for i in range(12):
    plt.subplot(2, 6, i+1)
    plt.imshow(Xtr[i, :, :, 0]/2+0.5, cmap='gray')
    plt.title(str(Ytr[i].argmax()))
    plt.axis('off')
plt.suptitle('MNIST')
plt.show()
```

![MNIST dataset](/img/2019-05/mnist.png)

Statistics are [known to lie](http://www.tylervigen.com/spurious-correlations). Even experts can be misled by statistics. For example, it is well-known that early diagnosis increases cancer survival rate, right? Actually, [a medical study](https://www.ncbi.nlm.nih.gov/pubmed/10865276) has found that the numbers have been inflated by not thinking carefully about statistics.

---------------------------------------------------------------------------------------------------------

Let us start by building the *discriminator* **D.**

Remember, this model is given an image and must say whether it is fake or real. We will use a sigmoid to output a probability, [0,1].

$$D\colon [-1,1]^{28\times 28\times 1} \rightarrow [0, 1]$$

```python
x = input_layer = layers.Input((28, 28, 1))

# Three convolutions with stride=2 are used to downsample the image.
for _ in range(3):
    x = layers.Conv2D(64, 3, strides=2, padding='same')(x)
    x = layers.LeakyReLU(0.1)(x)

# Fully-connected layer
x = layers.Flatten()(x)
x = layers.Dense(500)(x)
x = layers.LeakyReLU(0.1)(x)
x = layers.Dropout(0.5)(x)

# Output=sigmoid
x = layers.Dense(1, activation='sigmoid')(x)  # Notice sigmoid used in the output.

D = models.Model(input_layer, x)
D.summary()
```

As, for the *generator* **G,** we will produce an image given a noise vector $$z$$ of size 100,

$$G\colon\mathbb R^{100}\rightarrow[-1,1]^{28\times 28\times 1}.$$

```python
x = input_layer = layers.Input([100])

# Enlarge and reshape vector [100] into activations with shape [7, 7, 64].
x = layers.Dense(7 * 7 * 64)(x)
x = layers.Reshape((7, 7, 64))(x)

# Apply two transpose convolutions, each double the size of the activation map.
# Batch normalization is also used to foment stochasticity.
for i in range(2):
    x = layers.Conv2DTranspose(64, 5, strides=2, padding='same')(x)
    x = layers.BatchNormalization(momentum=0.9)(x)
    x = layers.LeakyReLU(0.1)(x)

# Finally, a tanh activation is applied so the output is within [-1, 1].
x = layers.Conv2D(1, 1, activation='tanh')(x)

G = models.Model(input_layer, x)
G.summary()
```

We must now specify the losses, $$L_D$$ and $$L_G$$, which these two models try to minimize.

We can decompose the aforementioned minimax problem into its two components:

$$L_D = -(\log D(\mathbf x) + \log(1-D(G(\mathbf z)))),$$

$$L_G = -\log(D(G(\mathbf z))).$$

```python
x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))
z = tf.placeholder(tf.float32, shape=(None, 100))

# For numerical stability reasons, we will clip values before calling log
clip_log = lambda x: tf.log(tf.clip_by_value(x, 1e-7, 1-1e-7))

D.loss = -tf.reduce_mean(clip_log(D(x)) + clip_log(1-D(G(z))))
G.loss = -tf.reduce_mean(clip_log(D(G(z))))

D.opt = tf.train.MomentumOptimizer(0.001, momentum=0.9).minimize(D.loss, var_list=D.trainable_weights)
G.opt = tf.train.AdamOptimizer(0.0002, 0.5).minimize(G.loss, var_list=G.trainable_weights)
```

Until the upcoming TensorFlow 2.0, we need to work with sessions. The session is the context within which computations are evaluated in the GPU.

```python
sess = backend.get_session()
sess.run(tf.global_variables_initializer())
```

A few definitions on the batch size and steps.

```python
batch_size = 64  # reduce this number if you have out-of-memory (OOM) errors
steps = len(Xtr) // batch_size
z_debug = np.random.randn(11, 100)
```

Finally,
1. we need to train the discriminator by sampling a few images from the dataset and the generator.
2. we need to train the generator by evaluating sampled images using the discriminator.

```python
for step in range(steps):
    # 1. Train the discriminator.

    # sample the dataset and noise
    _x = Xtr[np.random.randint(0, len(Xtr), batch_size//2)]
    _z = np.random.randn(batch_size//2, 100)

    # run the optimizer which will minimize the loss
    sess.run(D.opt, {x: _x, z: _z})

    # 2. Train the generator

    # sample noise
    _z = np.random.randn(batch_size, 100)

    # run the optimizer which will minimize the loss
    sess.run(G.opt, {z: _z})

    # show intermediate results
    if step % 10 == 0:
        Xhat = G.predict(z_debug)
        P = D.predict(Xhat)
        for k in range(11):
            plt.subplot(2, 6, k+1)
            plt.imshow(Xhat[k, :, :, 0]/2+0.5, cmap='gray')
            plt.title('P=%.2f' % P[k])
            plt.axis('off')

        H1 = D.predict(G.predict(np.random.randn(50, 100)))
        H2 = D.predict(Xtr[np.random.randint(0, len(Xtr), 50)])

        plt.subplot(2, 6, 12)
        plt.hist(H1, label='fake', range=(0, 1), alpha=0.5)
        plt.hist(H2, label='real', range=(0, 1), alpha=0.5)
        plt.legend()
        plt.title('Discriminator')
        plt.suptitle('%d / %d' % (step, steps))
        plt.show()
```

![GAN training](/img/2019-05/gan.gif)

Feel free to make it train for a looooonger time!

GANs benefit from long training times. The more you train, the better!

Training a GAN is not easy. There are two big problems:

1. **Mode collapse:** the generator ignores the noise and starts producing the same output at each step targeting a single vulnerability in the discriminator.
2. **Vanishing gradient:** if the discriminator becomes too good, the gradient that is chained into the generator might become too small.

Some general tricks to train a GAN are provided [in this page](https://github.com/soumith/ganhacks) and this [paper by Goodfellow](http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf):

1. **Label flipping:** some people flip label so that the discriminator predicts 0 instead of 1, and vice-verse, with a small probability, such as p=0.05.
2. **Positive label smoothing:** make the discriminator predict 0.9 instead of 1. Some people also smooth 0 to 0.1, but Goodfellow claims this is unhelpful.
3. **Noisy dataset:** add random noise to the dataset so that the discriminator becomes robust to small noise.
4. **Historical average:** a simpler approach to this technique is to train the discriminator using past images from the generator.
5. **Train the discriminator more:** it is common to train the discriminator more times than the generator. Usually, the discriminator is updated 5 times for each time the generator is updated.
6. **GAN loss:** most importantly, many, many people have suggested changes to the traditional GAN loss.

We will now focus on point 6. While there is yet no consensus on what GAN loss works best, we are going to present next two recent alternatives.

## LSGAN

Least Squares GAN uses L2 instead of sigmoid-crossentropy.

$$L_D = (D(\mathbf x)-1)^2 + D(G(\mathbf z))^2$$
$$L_G = D(G(\mathbf z)-1)^2$$

According to the authors, there are two advantages:

1. LSGAN penalizes the generator if the samples are inside discriminator's correct boundary. It forces the generator's boundary to be closer to the real data manifold.
2. Vanishing gradients are reduced by the fact that the loss is relative to the boundary distance.

The paper:

* Mao, Xudong, et al. "[Least squares generative adversarial networks.](http://openaccess.thecvf.com/content_iccv_2017/html/Mao_Least_Squares_Generative_ICCV_2017_paper.html)" Proceedings of the IEEE International Conference on Computer Vision. 2017.

```python
D.loss = tf.reduce_mean((D(x) - 1)**2 + D(G(z))**2)
G.loss = tf.reduce_mean((D(G(z)) - 1)**2)
```

## WGAN-GP

Between the many, many different GAN losses that have been proposed, WGAN-GP [has distinguish itself](https://towardsdatascience.com/gan-ways-to-improve-gan-performance-acf37f9f59b).

WGAN-GP is an improvement of another paper which introduced the WGAN loss. The idea is to approximation the Wasserstein Distance, which measures the distance between two probability distributions, in this case the generator and discriminator distributions.

$$L_D = D(\mathbf{\tilde x}) - D(\mathbf x) + \lambda(\|\nabla_{\mathbf{\hat x}}D(\mathbf{\hat x})\|_2-1)^2$$

$$L_G = -D(\mathbf{\tilde x})$$

where:

- $$\tilde x = G(z)$$
- $$\hat x = \varepsilon x + (1-\varepsilon) \tilde x$, with $\varepsilon \sim U(0,1)$$
- Usually, $$\lambda=10$$

The first two terms of the loss (the difference) represent the Wasserstein Distance. The discriminator must be a  1-Lipschitz function for this difference to represent the Wasserstein Distance. For that to be the case, the norm of the gradient must be 1.

* Gulrajani, Ishaan, et al. "[Improved Training of Wasserstein GANs.](https://arxiv.org/abs/1704.00028)" Advances in Neural Information Processing Systems. 2017.

```python
x_tilde = G(z)
epsilon = tf.random.uniform([tf.shape(x_tilde)[0], 1, 1, 1])
x_circ = epsilon*x + (1-epsilon)*x_tilde

norm_grads = tf.sqrt(tf.reduce_sum(tf.gradients(D(x_circ), x_circ)[0] ** 2, [1, 2, 3]))
D.loss = tf.reduce_mean(D(x_tilde) - D(x) + 10*((norm_grads - 1)**2))
G.loss = -tf.reduce_mean(D(x_tilde))
```

-------------------------------------------------------------------------------------------------------

## Fréchet Inception Distance

To measure the quality of the GAN output, the Fréchet Inception Distance (FID) is becoming the standard. It is an improvement of an older metric known as the Inception Distance.

In this metric, the last Inception-v3 pooling layer is compared between the real and generated samples. (The lower, the better.)

$$\text{FID} = \|\mu_r-\mu_g\|_2^2 + \text{tr}(\Sigma_r + \Sigma_g - 2\sqrt{\Sigma_r\Sigma_g}),$$

where $$\mu$$ and $$\Sigma$$ are obtained from a multi-variate Gaussian estimated by the 2048 pooling activations from samples from the dataset and from the generator. $$\text{tr}$$ is the [trace](https://en.wikipedia.org/wiki/Trace_(linear_algebra)) of the matrix.

In our case, we are going to use the first pooling layer because MNIST images are too small for much pooling.

* Heusel, Martin, et al. "[Gans trained by a two time-scale update rule converge to a local nash equilibrium.](https://arxiv.org/abs/1706.08500)" Advances in Neural Information Processing Systems. 2017.

```python
from scipy.stats import multivariate_normal
from scipy.linalg import sqrtm
from tensorflow.keras.applications.inception_v3 import InceptionV3
inception = InceptionV3(False)
```

Since MNIST images are grayscale, we have to add 3 channels because Inception is trained in color images.

```python
Xts = np.repeat(Xts, 3, 3)
```

```python
# If you want to use the last pooling layer, like in the paper, change [1] to [-1].
i = np.where(['pool' in l.name for l in inception.layers])[0][1]
inception2 = models.Model(inception.input, inception.layers[i].output)

r = inception2.predict(Xts[:1000], 8).reshape((1000, -1))

Y = G.predict(np.random.randn(1000, 100), 8)
Y = np.repeat(Y, 3, 3)
g = inception2.predict(Y, 8).reshape((1000, -1))

mu_r = np.mean(r, 0)
mu_g = np.mean(g, 0)
sigma_r = np.cov(r, rowvar=0)
sigma_g = np.cov(g, rowvar=0)
FID = np.sum((mu_r - mu_g)**2) + np.trace(sigma_r + sigma_g - 2*sqrtm(sigma_r @ sigma_g))
print(FID)
```

## Conditional GANs

We can condition the output on a given input.

For example, in MNIST, we can specify that the generator must produce a digit of a given class.

To do this, the *discriminator* will be trained to correctly classify the class based on the training set, and the *generator* receives a given class as input and is penalized if it is unable to convince the discriminator of that class.

* Mirza, Mehdi, and Simon Osindero. "[Conditional generative adversarial nets.](https://arxiv.org/pdf/1411.1784.pdf)" arXiv preprint arXiv:1411.1784 (2014).

The *discriminator* **D** now outputs both the probability of the image being real and also its class. The class one-hot encoded (e.g. `2` is represented by a binary vector `(0, 0, 1, 0, 0, 0, 0)`). The new output is shown in <span style="border: 1px solid black">a box</span> below. We will use a [softmax](https://en.wikipedia.org/wiki/Softmax_function) on the class output to force the class probability to sum up to 1.

$$D\colon [-1,1]^{28\times 28\times 1} \rightarrow [0, 1]\times\boxed{[0, 1]^K}$$

```python
x = input_layer = layers.Input((28, 28, 1))

for _ in range(3):
    x = layers.Conv2D(64, 3, strides=2, padding='same')(x)
    x = layers.LeakyReLU(0.1)(x)

x = layers.Flatten()(x)
x = layers.Dense(500)(x)
x = layers.LeakyReLU(0.1)(x)
x = layers.Dropout(0.5)(x)

disc_output = layers.Dense(1, activation='sigmoid')(x)  # Probability of image being real
class_output = layers.Dense(10, activation='softmax')(x)  # Probability of being of class k

D = models.Model(input_layer, [disc_output, class_output])
D.summary()
```

As, for the *generator* **G,** we will produce an image given a noise vector $$z$$ of size 100 as well as the new class one-hot encoded vector which is represented in <span style="border: 1px solid black">a box</span>,

$$G\colon\mathbb R^{100}\times\boxed{\mathbb R^{10}}\rightarrow[-1,1]^{28\times 28\times 1}.$$

```python
input_noise = layers.Input([100])  # Noise input
input_class = layers.Input([10])   # Class input

# Concatenate both inputs
x = layers.Concatenate()([input_noise, input_class])

x = layers.Dense(7 * 7 * 64)(x)
x = layers.Reshape((7, 7, 64))(x)

for i in range(2):
    x = layers.Conv2DTranspose(64, 5, strides=2, padding='same')(x)
    x = layers.BatchNormalization(momentum=0.9)(x)
    x = layers.LeakyReLU(0.1)(x)

x = layers.Conv2D(1, 1, activation='tanh')(x)

G = models.Model([input_noise, input_class], x)
G.summary()
```

We will now need to specify two new inputs: the true class output, $$\mathbf y$$, and a random class to give the generator, $$\mathbf r$$.

On the other hand, the discriminator now has two outputs: the probability of the class being real, $$\hat p$$, and a vector of probabilities of the image belong to each class, $$\mathbf{\hat k}$$.

```python
x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))
y = tf.placeholder(tf.float32, shape=(None, 10))
z = tf.placeholder(tf.float32, shape=(None, 100))
r = tf.placeholder(tf.float32, shape=(None, 10))

# We distinguish discriminator probabilities for the dataset (px and kx) from those of images
# created by the generator (pg and kg).
px, kx = D(x)
pg, kg = D(G([z, r]))
```

We will now add a new term (which is highlighted in a box) to the loss to punish the class, which must be specified during training,

$$L_D'(\mathbf x, \mathbf y) = L_D(\mathbf x) - \boxed{\sum_{i=1}^Ky_i\log(\hat k_i)}.$$

Notice that we only punish the discriminator if it fails to recognize the class from dataset images, not the class from images provided by the generator.

```python
# For numerical stability reasons, we will clip values before calling log
clip_log = lambda x: tf.log(tf.clip_by_value(x, 1e-7, 1-1e-7))

old_loss = clip_log(px) + clip_log(1-pg)
new_term = tf.reduce_sum(y*clip_log(kx), 1)
D.loss = -tf.reduce_mean(old_loss + new_term)
```

With regard to the generator, it will be punished if it fails to produces images of a class `kg` that the discriminator is able to identify,

$$L_G'(\mathbf z, \mathbf r) = L_G(\mathbf z) - \boxed{\sum_{i=1}^Kr_i\log(\hat k_i)}.$$

```python
old_loss = clip_log(pg)
new_term = tf.reduce_sum(r*clip_log(kg), 1)
G.loss = -tf.reduce_mean(old_loss + new_term)

D.opt = tf.train.MomentumOptimizer(0.001, momentum=0.9).minimize(D.loss, var_list=D.trainable_weights)
G.opt = tf.train.AdamOptimizer(0.0002, 0.5).minimize(G.loss, var_list=G.trainable_weights)

sess = backend.get_session()
sess.run(tf.global_variables_initializer())
```

The training cycle is pretty much the same as before, except we now have the extra inputs: `y_k` and `r_k` to specify the real and generated classes, respectively.

```python
batch_size = 64  # reduce this number if you have out-of-memory (OOM) errors
steps = len(Xtr) // batch_size
z_debug = np.random.randn(10, 100)
r_debug = utils.to_categorical(np.arange(10, dtype=int))

for step in range(steps):
    # 1. Train the discriminator.

    # sample the dataset and noise
    ix = np.random.randint(0, len(Xtr), batch_size//2)
    _x = Xtr[ix]
    _y = Ytr[ix]
    _z = np.random.randn(batch_size//2, 100)
    _r = utils.to_categorical(np.random.randint(0, 10, batch_size//2), 10)

    # run the optimizer which will minimize the loss
    sess.run(D.opt, {x: _x, z: _z, y: _y, r: _r})

    # 2. Train the generator

    # sample noise
    _z = np.random.randn(batch_size, 100)
    _r = utils.to_categorical(np.random.randint(0, 10, batch_size), 10)

    # run the optimizer which will minimize the loss
    sess.run(G.opt, {z: _z, r: _r})

    # show intermediate results
    if step % 10 == 0:
        Xhat = G.predict([z_debug, r_debug])
        P = D.predict(Xhat)
        for k in range(10):
            plt.subplot(2, 6, k+1)
            plt.imshow(Xhat[k, :, :, 0]/2+0.5, cmap='gray')
            plt.title('$\\bf{%d}$ | Pr=%.2f Pk=%.2f' % (k, P[0][k], P[1][k, k]))
            plt.axis('off')

        plt.subplot(2, 6, 11)
        ix = np.random.randint(0, len(Xtr), 1000)
        Dacc = np.mean(D.predict(Xtr[ix])[1].argmax(1) == Ytr[ix].argmax(1))
        plt.text(0.5, 0.8, 'Disc class accuracy:', ha='center')
        plt.text(0.5, 0.7, '%d%%' % (Dacc*100), ha='center')
        plt.axis('off')

        zr = [np.random.randn(50, 100), utils.to_categorical(np.random.randint(0, 10, 50), 10)]
        plt.subplot(2, 6, 12)
        plt.hist(D.predict(G.predict(zr))[0], label='fake', range=(0, 1), alpha=0.5)
        plt.hist(D.predict(Xtr[np.random.randint(0, len(Xtr), 50)])[0], label='real', range=(0, 1), alpha=0.5)
        plt.legend()
        plt.title('Discriminator')
        plt.suptitle('%d / %d' % (step, steps))
        plt.show()
```

![CGAN training](/img/2019-05/cgan.gif)

In the plot titles, we show `Pr` which is $$\text P(\text{real})$$ and `Pk` which is $\text P(\text{class})$, as evaluated by the discriminator.

Notice how it was faster to produce good results now. The more homogenous and the more help (in the form of conditions or otherwise) we can provide the GAN, the easier it is to converge.

---------------------------------------------------------------------------------------------------------

## Conditional GAN (Pix2Pix)

Pix2Pix is a type of conditional GAN where the input condition is an image (typically, a user-drawn segmentation) and the output is, of course, also an image as before. Some examples from the paper:

<img src="/img/2019-05/pix2pix.png" width="1022" height="377">

* Isola, Phillip, et al. "[Image-to-image translation with conditional adversarial networks.](http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf)" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017. [[web page](https://affinelayer.com/pixsrv/)]

For this work, we are going to use the [CMP Facade dataset](http://cmp.felk.cvut.cz/~tylecr1/facade/), which has almost 400 images and have been resized to 64x64 by us.

Matrix `X` has the images (N, 64, 64, 3).

Matrix `Y` is a (N, 64, 64) array where each value is [0, 11] depending on the segmentation it represents:

Download and unzip them:

```
!wget http://cmp.felk.cvut.cz/~tylecr1/facade/CMP_facade_DB_base.zip
!wget http://cmp.felk.cvut.cz/~tylecr1/facade/CMP_facade_DB_extended.zip
!unzip -qqn CMP_facade_DB_base.zip
!unzip -qqn CMP_facade_DB_extended.zip
```

Load the images (X) and the segmentation (Y).

```python
SIZE = (256, 256)

print('Loading the .jpg images...')

def load(dirname, x):
    x = os.path.join(dirname, x)
    return resize(imread(x), SIZE, mode='constant', anti_aliasing=True)

X = [load('base', f) for f in sorted(os.listdir('base')) if f.endswith('.jpg')]
X += [load('extended', f) for f in sorted(os.listdir('extended')) if f.endswith('.jpg')]
X = np.array(X)

print('Loading the .png segmentations...')

def load(dirname, x):
    x = os.path.join(dirname, x)
    return resize(imread(x), SIZE, order=0, mode='constant', anti_aliasing=False, preserve_range=True)

Y = [load('base', f) for f in sorted(os.listdir('base')) if f.endswith('.png')]
Y += [load('extended', f) for f in sorted(os.listdir('extended')) if f.endswith('.png')]
Y = np.array(Y)
```

We will flip images horizontally as data augmentation:

```python
X = np.concatenate((X, np.flip(X, 2)))
Y = np.concatenate((Y, np.flip(Y, 2)))
```

Draw them:

```python
for i in range(6):
    plt.subplot(2, 6, i+1)
    plt.imshow(Y[i]/11, cmap='gray')
    plt.title('Input')
    plt.axis('off')

    plt.subplot(2, 6, i+7)
    plt.imshow(X[i]/2+0.5)
    plt.title('Output')
    plt.axis('off')
plt.suptitle('CMP-Facade')
plt.show()
```

![CMP Facade dataset](/img/2019-05/cmp-facade.png)

Let us define a function to convert this mask, which is a (64, 64) matrix into a (64, 64, 12) binary tensor.

```python
def mask(Y):
    return np.rollaxis(np.array([[y == k for k in range(12)] for y in Y]), 1, 4)
```

The *generator* **G** is an U-Net. An [U-Net](https://arxiv.org/abs/1505.04597) is a neural network architecture that receives an image and outputs an image. It was originally conceived for semantic segmentation. Given a medical image, it outputs a grayscale image representing the probability of each pixel being the region of interest.

This architecture is composed by two parts: half of the network applies convolutions and successively reduces the input image (*encoder*) and the other half successively increases the size of the image (*decoder*). In the end, we have an output image with the same size as the input image, but the number of channels might be different (e.g. the input might be grayscale and the output can be RGB).

![UNet diagram](/img/2019-05/unet.png)

This size of the activation map along the network is symmetric. That is, the size of the activation map in the 2nd layer is equal to the size of the penultimate layer. The authors took advantage of this fact to introduce skip-connections to further improve the performance of the networks. What this skip-connections do is to connect each layer not only to the previous layer, but also to its twin layer. This allows gradients to travel more freely (avoiding things like vanishing gradients) and also helps avoid checkboard artifacts which sometimes plagues this type of networks.

Notice that now, noise is no longer given as an input. For that reason, in order to promote stochasticity, we will continue using batch normalization in the generator, and will now also use Dropout enabled both during training *and* testing, as the authors suggest.

```python
x = input_layer = layers.Input((64, 64, 12))

# encoder
skip_connections = []
for i in range(3):
    skip_connections.append(x)
    x = layers.Conv2D(64, 5, strides=2, padding='same')(x)
    x = layers.BatchNormalization(momentum=0.9)(x)
    x = layers.LeakyReLU(0.1)(x)
    x = layers.Dropout(0.1)(x, training=True)

# decoder
for i in range(3):
    x = layers.Conv2DTranspose(64, 5, strides=2, padding='same')(x)
    x = layers.BatchNormalization(momentum=0.9)(x)
    x = layers.LeakyReLU(0.1)(x)
    x = layers.Concatenate()([skip_connections[-i-1], x])

x = layers.Conv2D(3, 1, activation='tanh')(x)

G = models.Model(input_layer, x)
G.summary()
```

As for the *discriminator* **D,** the authors invent an architecture they call *PatchGAN*, which they claim improves quality. Instead of classifying the entire image as real or fake, the PatchGAN classifies individual small patches from the image, and then does the average between all those patches.

The PatchGAN can be implemented as a few convolutions followed by a sigmoid output. That is, instead of cropping the image in 70x70 patches, a similar result may be obtained by applying convolutions until the receptive field of each activation is 70x70. The activations are then averaged in the loss.

In any case, since we are already working with images of small size (64x64), we will use a traditional classifier as the discriminator.

```python
x = input_layer = layers.Input((64, 64, 3))

for _ in range(4):
    x = layers.Conv2D(64, 3, strides=2, padding='same')(x)
    x = layers.LeakyReLU(0.1)(x)

x = layers.Flatten()(x)
x = layers.Dense(128)(x)
x = layers.LeakyReLU(0.1)(x)
x = layers.Dropout(0.5)(x)

x = layers.Dense(1, activation='sigmoid')(x)

D = models.Model(input_layer, x)
D.summary()
```

We will now implement the same loss as before, except that now noise is no longer given as input. In its place, a segmentation $$\mathbf y$$ is given as input.

To help the GAN, the article suggests also adding an **L1 loss**,

$$L_G'(\mathbf x, \mathbf y) = L_G(\mathbf y) + \lambda\Sigma|\mathbf x-G(\mathbf y)|.$$

In the paper, the authors use $$\lambda=10$$, which we will also use. As explained before, this term, which is inspired by auto-encoders, helps the GAN converge. While the L2-norm is convex and so easier for gradient descent to optimize for, the authors chose to go with the L1-norm to avoid a blurring effect in the images.

```python
# Input
x = tf.placeholder(tf.float32, shape=(None, 64, 64, 3))
y = tf.placeholder(tf.float32, shape=(None, 64, 64, 12))

# For numerical stability reasons, we will clip values before calling log
clip_log = lambda x: tf.log(tf.clip_by_value(x, 1e-7, 1-1e-7))

x_hat = G(y)
D.loss = -tf.reduce_mean(clip_log(D(x)) + clip_log(1-D(x_hat)))
G.loss = tf.reduce_mean(-clip_log(D(x_hat)) + 10*tf.reduce_sum(tf.abs(x - x_hat), [1, 2, 3]))

D.opt = tf.train.MomentumOptimizer(0.001, momentum=0.9).minimize(D.loss, var_list=D.trainable_weights)
G.opt = tf.train.AdamOptimizer(0.0002, 0.5).minimize(G.loss, var_list=G.trainable_weights)

sess = backend.get_session()
sess.run(tf.global_variables_initializer())
```

The training cycle goes similarly to before.

```python
batch_size = 16  # reduce this number if you have out-of-memory (OOM) errors
steps = 10 * (len(X) // batch_size)
ix = np.random.randint(0, len(Y), 5)
x_debug = X[ix]
y_debug = Y[ix]
m_debug = mask(y_debug)

for step in range(steps):
    # 1. Train the discriminator.

    # sample the dataset and condition
    _x = X[np.random.randint(0, len(X), batch_size//2)]
    _y = mask(Y[np.random.randint(0, len(Y), batch_size//2)])

    # run the optimizer which will minimize the loss
    sess.run(D.opt, {x: _x, y: _y})

    # 2. Train the generator

    # sample a condition and respective image
    ix = np.random.randint(0, len(X), batch_size)
    _x = X[ix]
    _y = mask(Y[ix])

    # run the optimizer which will minimize the loss
    sess.run(G.opt, {x: _x, y: _y})

    # show intermediate results
    if step % 10 == 0:
        X_hat = G.predict(m_debug)
        for k in range(5):
            plt.subplot(3, 6, k+1)
            plt.imshow(y_debug[k]/11, cmap='gray')
            plt.title('Input')
            plt.axis('off')

            plt.subplot(3, 6, k+7)
            plt.imshow(X_hat[k]/2+0.5)
            plt.title('Predicted Output')
            plt.axis('off')

            plt.subplot(3, 6, k+13)
            plt.imshow(x_debug[k]/2+0.5)
            plt.title('Real Output')
            plt.axis('off')

        plt.subplot(2, 6, 12)
        Z = mask(Y[np.random.randint(0, len(Y), 50)])
        plt.hist(D.predict(G.predict(Z)), label='fake', range=(0, 1), alpha=0.5)
        plt.hist(D.predict(X[np.random.randint(0, len(X), 50)]), label='real', range=(0, 1), alpha=0.5)
        plt.legend()
        plt.title('Discriminator')
        plt.suptitle('%d / %d' % (step, steps))
        plt.show()
```

![Pix2Pix training](/img/2019-05/pix2pix.gif)

---------------------------------------------------------------------------------------------------------

## Cycle GANs

Better to clear existing models before proceeding:

In this work, the idea is to go one step further than the Conditional GAN. Instead of converting an image into another (*paired* conversion), the idea is to convert an entire collection of images into another collection (*unpaired* conversion).

Examples from the paper:

<img src="/img/2019-05/cyclegan.jpg" width="1022" height="497">

* Zhu, Jun-Yan, et al. "[Unpaired image-to-image translation using cycle-consistent adversarial networks.](https://arxiv.org/pdf/1703.10593.pdf)" Proceedings of the IEEE international conference on computer vision. 2017. [[web page](https://junyanz.github.io/CycleGAN/)]

**Two** generators and **two** discriminators are trained. Generator $$G$$ converts images $$X$$ into images $$Y$$ ($$G\colon X \rightarrow Y$$), while another generator $$F$$ converts images $$Y$$ into images $$X$$ ($$F\colon Y \rightarrow X$$). Then the discriminators $$D_X$$ and $$D_Y$$ try to distinguish images $$X$$ and $$Y$$, respectively.

We are going to use the [horse2zebra dataset](https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/).

```python
X = (np.array([imread(os.path.join('trainA', x) for x in os.listdir('trainA')])/127.5-1).astype(np.float32)
Y = (np.array([imread(os.path.join('trainB', x) for x in os.listdir('trainB')])/127.5-1).astype(np.float32)

# As simple data augmentation, images are flipped horizontally
X = np.concatenate((X, np.flip(X, 2)))
Y = np.concatenate((Y, np.flip(Y, 2)))

for i in range(6):
    # X (horse)
    plt.subplot(2, 6, i+1)
    plt.imshow(X[i]/2+0.5)
    plt.axis('off')
    plt.title('horse')

    # Y (zebra)
    plt.subplot(2, 6, i+7)
    plt.imshow(Y[i]/2+0.5)
    plt.axis('off')
    plt.title('zebra')
plt.suptitle('horse2zebra')
plt.show();
```

![Horse-2-Zebra dataset](/img/2019-05/horse2zebra.png)

We are going to use more filters than before, since this task is more complex, and some more complicated layers.

```python
def ReflectionPadding2D(pad):
    return layers.Lambda(lambda x: tf.pad(x, [[0, 0], [pad, pad], [pad, pad], [0, 0]], 'REFLECT'))

def InstanceNormalization():
    return layers.Lambda(lambda x: tf.contrib.layers.instance_norm(x))

def create_generator():
    x = input_layer = layers.Input((64, 64, 3))

    x = ReflectionPadding2D(3)(x)
    x = layers.Conv2D(32, 7, 1, 'valid')(x)
    x = InstanceNormalization()(x)
    x = layers.Activation('relu')(x)

    for filters in [64, 128]:
        x = layers.Conv2D(filters, 3, 2, 'same')(x)
        x = InstanceNormalization()(x)
        x = layers.Activation('relu')(x)

    for _ in range(6):
        x0 = x
        # first layer
        x = ReflectionPadding2D(1)(x)
        x = layers.Conv2D(128, 3, 1, 'valid')(x)
        x = InstanceNormalization()(x)
        x = layers.Activation('relu')(x)
        # second layer
        x = ReflectionPadding2D(1)(x)
        x = layers.Conv2D(128, 3, 1, 'valid')(x)
        x = InstanceNormalization()(x)
        # merge
        x = layers.Add()([x, x0])

    for filters in [64, 32]:
        x = layers.Conv2DTranspose(filters, 3, 2, 'same')(x)
        x = InstanceNormalization()(x)
        x = layers.Activation('relu')(x)

    x = ReflectionPadding2D(3)(x)
    x = layers.Conv2D(3, 7, 1)(x)
    x = layers.Activation('tanh')(x)

    return models.Model(input_layer, x)

def create_discriminator():
    x = input_layer = layers.Input((64, 64, 3))

    x = layers.Conv2D(64, 4, 2, 'same')(x)
    x = layers.LeakyReLU(0.2)(x)

    for filters in [128, 256, 512]:
        x = layers.Conv2D(64, 4, 2, 'same')(x)
        x = InstanceNormalization()(x)
        x = layers.LeakyReLU(0.2)(x)

    '''
    # If you prefer a PatchGAN
    x = Conv2D(1, 4, 1, 'same')(x)
    x = layers.Lambda(lambda x: tf.reduce_mean(x, [1, 2, 3]))(x)
    '''

    x = layers.Flatten()(x)
    x = layers.Dense(1)(x)

    return models.Model(input_layer, x)

G = create_generator()  # X -> Y
F = create_generator()  # Y -> X
print('Generator:')
G.summary()

print()
Dx = create_discriminator()
Dy = create_discriminator()
print('Discriminator:')
Dx.summary()
```

Three losses are involved:

1. $$L_{GAN}(G, D_Y, X, Y)$$
2. $$L_{GAN}(F, D_X, Y, X)$$
3. $$L_{cyc}(G, F) = \Sigma|F(G(X))-X| + \Sigma|G(F(Y))-Y|$$

The first two are traditional GAN losses, with each generator using its own discriminator for its loss. The third loss is an extra loss to help the GAN process converge. It uses L1, like Pix2Pix, except that here results are unpaired, therefore one generators converts a zebra to a horse, and the other tries to do the inverse, and the final image is minimized against the initial zebra.

Like in the paper, we will use $$\lambda=10$$ as the weight for this third loss.

First, let us define the inputs:

```python
x = tf.placeholder(tf.float32, shape=(None, 64, 64, 3))  # horse
y = tf.placeholder(tf.float32, shape=(None, 64, 64, 3))  # zebra
```

Again, for numerical stability reasons, we will create a log version with clipped values:

```python
clip_log = lambda x: tf.log(tf.clip_by_value(x, 1e-7, 1-1e-7))
```

To avoid code repetition, let us define the losses as functions:

```python
def D_loss(G, D, x, y):
    #return -(clip_log(D(y)) + clip_log(1-D(G(x))))  # classic
    return (D(y) - 1)**2 + D(G(x))**2  # LSGAN

def GAN_loss(G, D, x):
    #return -clip_log(D(G(x)))  # classic
    return (D(G(x)) - 1)**2  # LSGAN

def Cyc_loss(G, F, y):
    return tf.reduce_sum(tf.abs(G(F(y)) - y), [1, 2, 3])

Dy.loss = tf.reduce_mean(D_loss(G, Dy, x, y))
Dx.loss = tf.reduce_mean(D_loss(F, Dx, y, x))

lambda_ = 10
G.loss = tf.reduce_mean(GAN_loss(G, Dy, x) + lambda_*Cyc_loss(G, F, y))
F.loss = tf.reduce_mean(GAN_loss(F, Dx, y) + lambda_*Cyc_loss(F, G, x))

#Dy.opt = tf.train.MomentumOptimizer(0.001, momentum=0.9).minimize(Dy.loss, var_list=Dy.trainable_weights)
#Dx.opt = tf.train.MomentumOptimizer(0.001, momentum=0.9).minimize(Dx.loss, var_list=Dx.trainable_weights)
Dy.opt = tf.train.AdamOptimizer(0.0002, 0.5).minimize(Dy.loss, var_list=Dy.trainable_weights)
Dx.opt = tf.train.AdamOptimizer(0.0002, 0.5).minimize(Dx.loss, var_list=Dx.trainable_weights)
G.opt = tf.train.AdamOptimizer(0.0002, 0.5).minimize(G.loss, var_list=G.trainable_weights)
F.opt = tf.train.AdamOptimizer(0.0002, 0.5).minimize(F.loss, var_list=F.trainable_weights)

sess = backend.get_session()
sess.run(tf.global_variables_initializer())
```

As before, the training cycle is similar. One change is that we apply the common technique of updating the discriminators 5 times for each time the generators are updated.

```python
batch_size = 16  # reduce this number if you have out-of-memory (OOM) errors
steps = 100 * (len(X) // batch_size)
X_debug = X[np.random.randint(0, len(X), 5)]
Y_debug = Y[np.random.randint(0, len(Y), 5)]

def show_intermediate_results(title, G, D, X, Xh, Yh):
    Y_hat = G.predict(X)
    for k in range(5):
        plt.subplot(2, 6, k+1)
        plt.imshow(X[k]/2+0.5)
        plt.title('Original')
        plt.axis('off')

        plt.subplot(2, 6, k+7)
        plt.imshow(Y_hat[k]/2+0.5)
        plt.title('Predicted')
        plt.axis('off')

    plt.subplot(2, 6, 12)
    plt.hist(D.predict(G.predict(Xh)), 12, label='fake', range=(-0.1, 1.1), alpha=0.5)
    plt.hist(D.predict(Yh), 12, label='real', range=(-0.1, 1.1), alpha=0.5)
    plt.title('D vs G')
    plt.legend()

    plt.suptitle(title)
    plt.show()

for step in range(steps):
    # Update the discriminators 5 times for each time the generators are updated
    for _ in range(5):
        # 1. Train the discriminators

        # sample the two datasets
        _x = X[np.random.randint(0, len(X), batch_size//2)]
        _y = Y[np.random.randint(0, len(Y), batch_size//2)]

        # add some noise
        #_x += 0.05*np.random.randn(*_x.shape)
        #_y += 0.05*np.random.randn(*_y.shape)

        # run the optimizer which will minimize the loss
        sess.run(Dy.opt, {x: _x, y: _y})
        sess.run(Dx.opt, {x: _x, y: _y})

    # 2. Train the generators

    # sample the two datasets
    _x = X[np.random.randint(0, len(X), batch_size)]
    _y = Y[np.random.randint(0, len(Y), batch_size)]

    # run the optimizer which will minimize the loss
    sess.run(G.opt, {x: _x, y: _y})
    sess.run(F.opt, {x: _x, y: _y})

    # show intermediate results
    if step % 10 == 0:
        title = '%d / %d' % (step, steps)
        Xh = X[np.random.randint(0, len(X), 50)]
        Yh = Y[np.random.randint(0, len(Y), 50)]

        show_intermediate_results('horse -> zebra | ' + title, G, Dy, X_debug, Xh, Yh)
        show_intermediate_results('zebra -> horse | ' + title, F, Dx, Y_debug, Yh, Xh)
```

![Horse to Zebra training](/img/2019-05/horse2zebra.gif)

![Zebra to Horse training](/img/2019-05/zebra2horse.gif)

---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------

# Final Thoughts

GANs have become one of the most popular techniques to generate data. While generator methods have existed before, such as deep belief networks, these methods tried to estimate the data distribution directly, and the data generation was done by sampling from the distribution. Unfortunately, such direct methods do not produce data of this quality.

That being said, other generator methods have been developed. Variation Auto-Encoders can be used, where the latent variable space is a distribution, which can then be sampled to generate new samples. Also, some of the methods here presented, have been reproduced without requiring GANs. For example, much of Pix2Pix examples can be reproduced [using style transfer techniques](http://openaccess.thecvf.com/content_iccv_2017/html/Chen_Photographic_Image_Synthesis_ICCV_2017_paper.html).

Interesting to note is the fact that this actor-critic dynamic of the GANs has been used in other contexts. For example, a GAN loss term has been used to [improve semantic segmentation tasks](https://sgo-workshop.github.io/papers/16/sgo.pdf).

{% endraw  %}
