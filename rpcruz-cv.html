<html>
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
<title>[CV] Ricardo Cruz, PhD</title>

<style>
body {font-family: serif; max-width: 850px; margin: auto; margin-top: 20px; margin-bottom: 20px}
h1 {margin-bottom: 0}
h2 {border-bottom: 2px solid; font-variant: small-caps}
a {text-decoration: none}
a:hover {text-decoration: underline}
.sc {font-variant: small-caps}
.small {font-size: x-small}
.hl {background-color: yellow}
.nobr {white-space: nowrap}
.bigskip {margin-top: 30px}
ul.menu {background-color: white; position: fixed; top: 0; right: 0; list-style: none; padding-left: 20px; padding-right: 30px; border: 1px solid black; font-size: x-small}
ul.menu a {display: block}
@media screen and (min-width: 1000px) {body {margin: auto; text-align: justify} div.columns {display: flex; flex-direction: column} div.item {display: flex} div.left {width: 150px; font-weight: bold} div.right {flex: 1} .desktop {display: block}}
@media screen and (max-width: 999px) {body {margin-left: 6px; margin-right: 6px} .desktop {display: none} div.item {display: inline} div.left {display: inline; font-weight: bold} div.right {display: inline}}
</style>
</head>

<body id="top">
<h1>[CV] Ricardo Cruz, PhD</h1>
<img height="20px" src="imgs/profile-pdf.svg"> <a href="rpcruz-cv.pdf">PDF version</a> <img height="20px" src="imgs/profile-location.svg"> Valongo, Portugal <img height="20px" src="imgs/profile-email.svg"> <a href="mailto:ricardo.pdm.cruz@gmail.com">ricardo.pdm.cruz@gmail.com</a> <img height="20px" src="imgs/profile-phone.svg"> +351 934741617 <img height="20px" src="imgs/profile-website.svg"> <a href="https://rpmcruz.github.io">rpmcruz.github.io</a> <img height="20px" src="imgs/profile-orcid.svg"> <a href="https://orcid.org/0000-0002-5189-6228">0000-0002-5189-6228</a> <ul class="menu desktop">
<li><a href="#top">Top</a></li>
<li><a href="#education"><img style="width:1.5em" src="imgs/section-education.svg"> Education</a></li>
<li><a href="#employment"><img style="width:1.5em" src="imgs/section-employment.svg"> Employment</a></li>
<li><a href="#teaching"><img style="width:1.5em" src="imgs/section-teaching.svg"> Teaching</a></li>
<li><a href="#courses"><img style="width:1.5em" src="imgs/section-teaching.svg"> Courses</a></li>
<li><a href="#awards"><img style="width:1.5em" src="imgs/section-awards.svg"> Awards</a></li>
<li><a href="#selected-projects"><img style="width:1.5em" src="imgs/section-projects.svg"> Selected Projects</a></li>
<li><a href="#participation-in-scientific-projects"><img style="width:1.5em" src="imgs/section-scientific-projects.svg"> Participation in Scientific Projects</a></li>
<li><a href="#participation-in-scientific-events"><img style="width:1.5em" src="imgs/section-scientific-events.svg"> Participation in Scientific Events</a></li>
<li><a href="#participation-in-workshops-or-competitions"><img style="width:1.5em" src="imgs/section-scientific-events.svg"> Participation in Workshops or Competitions</a></li>
<li><a href="#impact-and-citations"><img style="width:1.5em" src="imgs/section-scientific-impact.svg"> Impact and Citations</a></li>
<li><a href="#conference-publications"><img style="width:1.5em" src="imgs/section-publications.svg"> Conference Publications</a></li>
<li><a href="#journal-publications"><img style="width:1.5em" src="imgs/section-publications.svg"> Journal Publications</a></li>
<li><a href="#collaborations-as-editor-or-evaluator"><img style="width:1.5em" src="imgs/section-scientific-impact.svg"> Collaborations as Editor or Evaluator</a></li>
<li><a href="#jury-participation"><img style="width:1.5em" src="imgs/section-jury-participation.svg"> Jury Participation</a></li>
<li><a href="#m.sc.-supervisions"><img style="width:1.5em" src="imgs/section-supervisions.svg"> M.Sc. Supervisions</a></li>
<li><a href="#b.sc.-projects-supervisions"><img style="width:1.5em" src="imgs/section-supervisions.svg"> B.Sc. Projects Supervisions</a></li>
</ul>
<p>Ricardo Cruz received a B.S. degree in computer science and an M.S. degree in applied mathematics, both from the University of Porto, Portugal. Since 2015, he has been a researcher at INESC TEC working in machine learning with particular emphasis on computer vision. He earned his Ph.D. in Computer Science in 2021 with a special emphasis on computer vision and deep learning. Currently, he is a post-doctoral researcher on autonomous driving under the THEIA research project, a partnership between the University of Porto and Bosch Car Multimedia.</p>
<p>Skills: Python • C • C++ • Java • R • MATLAB • PyTorch • TensorFlow • OpenCV • SQL • Git</p>
<p><img style="width:" src="imgs/lecture.jpg"></p>
<h2 id=education><img style="width:1.5em" src="imgs/section-education.svg"> Education</h2>
<div class="columns">
<div class="item"><div class="left">2021 Ph.D.</div><div class="right">Computer Science (joint degree University of Porto, Minho and Aveiro)</div></div>
<div class="item"><div class="left">2015 M.Sc.</div><div class="right">Mathematical Engineering (University of Porto)</div></div>
<div class="item"><div class="left">2012 B.Sc.</div><div class="right">Computer Science (University of Porto)</div></div>
</div>
<h2 id=employment><img style="width:1.5em" src="imgs/section-employment.svg"> Employment</h2>
<div class="columns">
<div class="item"><div class="left">2021--...</div><div class="right"><b>Post-doctoral Researcher</b> on Autonomous Driving<br>
University of Porto (FEUP) [in partnership with Bosch]</div></div>
<ul class="small">
<li>Collaboration between the University of Porto and Bosch Car Multimedia to improve autonomous driving perception</li>
<li>Developed frameworks for object detection using camera and LiDAR (2D discretization and raw point-clouds)</li>
<li>Published new methods for efficient semantic segmentation and ordinal regression</li>
<li>Supervised six master's theses, four bachelor's projects, and other team members</li>
<li>Responsible for the HPC infrastructure (using Slurm)</li>
</ul>
<div class="item"><div class="left">2015--2021</div><div class="right"><b>Research Assistant</b> on Machine Learning and Computer Vision<br>
INESC TEC</div></div>
<ul class="small">
<li>Research focus: re-thinking fundamentals about image classification and semantic segmentation (8+ publications)</li>
<li>Some highlights: (1) a method for background invariance using adversarial training, (2) new losses that minimize absolute trade-offs between Type 1 and 2 errors instead of relative trade-offs, (3) using backpropagation also for inference to refine existing outputs, (4) deploying learning-to-rank methods for class imbalance</li>
<li>Contributed to workshops, Summer School on Computer Vision (VISUM), and other events</li>
<li>Twice awarded "outstanding recognition" for organizing workshops and helping with the HPC infrastructure</li>
</ul>
<div class="item"><div class="left">2014</div><div class="right"><b>Research Grant</b> on Mathematical Modelling Research<br>
Mathematics Center of the University of Porto (CMUP)</div></div>
<ul class="small">
<li>Epidemiological models for HIV. A little of everything: from differential equations to stochastic simulations to cellular automata.</li>
</ul>
</div>
<h2 id=teaching><img style="width:1.5em" src="imgs/section-teaching.svg"> Teaching</h2>
<div class="columns">
<div class="item"><div class="left">2021--2022</div><div class="right"><b>Invited Auxiliary Professor,</b> University of Porto (FEUP)</div></div>
<div class="item"><div class="left">2018--2021</div><div class="right"><b>Invited Teacher Assistant,</b> University of Porto (FEUP)</div></div>
</div>
<h2 id=courses><img style="width:1.5em" src="imgs/section-teaching.svg"> Courses</h2>
<p>The teaching consisted of the pratical lessons (2h-4h per week) and helping with the materials. These courses took place during my PhD (as an Invited Teacher Assistant) and then as a Post-Doc (as an Invited Auxiliary Professor).</p>
<ul>
<li>L.EIC003: Programming Fundamentals (Python) [L.EIC] (2018/2019, 2019/2020, 2020/2021, 2021/2022) <a href="https://sigarra.up.pt/feup/pt/ucurr_geral.ficha_uc_view?pv_ocorrencia_id=484382"><img width="20px" src="imgs/link.svg"></a></li>
<li>L.EIC009: Programming (C/C++) [L.EIC] (2019/2020, 2020/2021) <a href="https://sigarra.up.pt/feup/pt/ucurr_geral.ficha_uc_view?pv_ocorrencia_id=459468"><img width="20px" src="imgs/link.svg"></a></li>
<li>L.EEC009: Data Structures and Algorithms (C/C++) [L.EEC] (2021/2022) <a href="https://sigarra.up.pt/feup/pt/ucurr_geral.ficha_uc_view?pv_ocorrencia_id=485369"><img width="20px" src="imgs/link.svg"></a></li>
</ul>
<h2 id=awards><img style="width:1.5em" src="imgs/section-awards.svg"> Awards</h2>
<div class="columns">
<div class="item"><div class="left">2022</div><div class="right"><b>Bosch for Mobility:</b> My students won Best New Participating Team in an autonomous driving competition <a href="https://noticias.up.pt/estudantes-da-u-porto-brilham-em-concurso-de-conducao-autonoma-da-bosch/"><img width="20px" src="imgs/link.svg"></a></div></div>
<div class="item"><div class="left">2021</div><div class="right"><b>INESC TEC Outstanding Recognition Award:</b> Monthly award for INESC TEC collaborators, for maintenance of the HPC infrastructure <a href="https://bip.inesctec.pt/en/especiaisdecorrida/ricardo-cruz-ctm-2/"><img width="20px" src="imgs/link.svg"></a></div></div>
<div class="item"><div class="left">2021</div><div class="right"><b>Pedagogic award (voted by students):</b> University of Porto (FEUP)</div></div>
<div class="item"><div class="left">2021</div><div class="right"><b>Best paper and presentation:</b> RECPAD conference <a href="https://noticias.up.pt/investigadores-da-u-porto-dominam-premios-do-recpad-2021/"><img width="20px" src="imgs/link.svg"></a></div></div>
<div class="item"><div class="left">2018</div><div class="right"><i></i>INESC TEC Outstanding Recognition Award: Monthly award for INESC TEC collaborators, for organizing workshops <a href="http://bip-archive.inesctec.pt/en/196/fora-de-serie.html"><img width="20px" src="imgs/link.svg"></a></div></div>
<div class="item"><div class="left">2017</div><div class="right"><b>Kaggle Bronze Medal (competition) and Silver (engagement)</b></div></div>
</div>
<h2 id=selected-projects><img style="width:1.5em" src="imgs/section-projects.svg"> Selected Projects</h2>
<p>See my github for more projects: <a href="https://github.com/rpmcruz?tab=repositories">github.com/rpmcruz</a>.</p>
<ul>
<li><b>Uber Pixor implementation.</b> Implementation of a popular bird's eye view LiDAR object detection model. <a href="https://github.com/rpmcruz/pixor"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>objdetect package.</b> Light-weight and versatile one-stage object detection framework. <a href="https://github.com/rpmcruz/objdetect"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>Human Feedback during Neural Network Training.</b> When a model makes a wrong prediction, a typical solution is to acquire more data related to the error &ndash; this is an expensive process known as active learning. Our proposal combines active learning with interpretability so the user can correct such mistakes while the model trains. This work resulted in a thesis that I supervised.</li>
<li><b>Neural Networks Robust to Background Changes.</b> While training an electrical insulator detector, we noticed a large drop in accuracy when going from the controlled studio (training set) to outdoors (testing set). The proposed method uses a background generator to generate adversarial backgrounds and a mask generator to introduce this background to the training image. A paper was published from this work. <a href="https://ieeexplore.ieee.org/abstract/document/9413004/"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>Annotation Aid Tool using GrabCut.</b> Annotations were necessary for a project whose goal was to learn a sequential segmentation model for the movement of mice. For that purpose, I developed a small tool to aid the annotation effort. The tool processes the video frames sequentially in two steps: (1) the annotator first selects the region where the mouse is, and (2) the annotator selects some positive pixels (left-click) and negative pixels (right-click) until he/she is satisfied with the segmentation produced by the GrabCut algorithm. <a href="https://github.com/rpmcruz/igrabcut"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>Classification of Cervical Cancer Risk.</b> Cervical cancer is the fourth leading cause of cancer-related deaths in women. The goal of the TAMI project was to automate cervical cancer screening via Pap smears. A non-parametric ordinal loss for neuronal networks was proposed to promote ordinal output probabilities (accuracy of 75.6% for seven classes and 81.3% for four classes). A paper was published based on this work. <a href="https://peerj.com/articles/cs-457/"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>Apoo (virtual machine) GTK+ interface.</b> I helped with the development of the GTK+ interface for Apoo (together with Profs Rogério Reis and Nelma Moreira), a virtual machine that is currently being used to teach Assembly. Apoo is written in Python and GTK+. <a href="https://www.dcc.fc.up.pt/~nam/apoo/node6.html"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>EatFeed.</b> RSS/Atom reader written in C++ and GTK+. <a href="https://github.com/rpmcruz/eatfeed"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>Google Summer of Code.</b> I was awarded twice a Google grant to work on open-source projects. LibreOffice dynamic layouts (2007) and YaST port from GTK+ to Qt (2006).</li>
<li><b>J2ME and Android games.</b> Games written in Java Mobile Edition; more recently, I ported a couple of them to Android. <a href="https://github.com/rpmcruz/android-games"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>SuperTux, co-author.</b> While in high-school, I was part of the initial team developing this game. It is written in C++, SDL, and OpenGL. <a href="https://www.supertux.org/"><img width="20px" src="imgs/link.svg"></a></li>
</ul>
<h2 id=participation-in-scientific-projects><img style="width:1.5em" src="imgs/section-scientific-projects.svg"> Participation in Scientific Projects</h2>
<ul>
<li>Post-doc researcher (2021&ndash;2023) on THEIA &ndash; Automated Perception Driving (POCI-01-0247-FEDER-047264) <a href="https://sigarra.up.pt/feup/pt/projectos_geral.ficha_projecto?p_id=78377"><img width="20px" src="imgs/link.svg"></a></li>
<li>Research member (2018&ndash;2021) of CLARE &ndash; Computer-aided cervical cancer screening (POCI-01-0145-FEDER-028857) <a href="https://www.inesctec.pt/pt/projetos/clare"><img width="20px" src="imgs/link.svg"></a></li>
<li>Masters research grant (2015&ndash;2016) on NanoSTIMA &ndash; Macro-to-Nano Human Sensing: Towards Integrated Multimodal Health Monitoring and Analytics (NORTE-01-0145-FEDER-000016)</li>
<li>Bachelors research grant on statistical epidemiological modelling (2014) (PEst-C/MAT/UI0144/2013)</li>
</ul>
<h2 id=participation-in-scientific-events><img style="width:1.5em" src="imgs/section-scientific-events.svg"> Participation in Scientific Events</h2>
<ul>
<li><b>5th International Conference on Sustainable Technologies for Industry 5.0</b> (STI 2023): Technical Program Committee member <a href="https://sti.green.edu.bd/committees"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>iMIMIC/MIL3ID/LABELS 2020 workshop proceedings</b> (MICCAI 2020): co-editor <a href="https://link.springer.com/book/10.1007/978-3-030-61166-8"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>iMIMIC 2020 workshop</b> (MICCAI 2020): committee sponsor chair <a href="https://imimic-workshop.com/previous_editions/2020/index.html"><img width="20px" src="imgs/link.svg"></a></li>
<li><b>3rd International Conference on Dynamics, Games and Science (2014):</b> president of the organizing committee <a href="https://www.fc.up.pt/dgsiii/"><img width="20px" src="imgs/link.svg"></a></li>
</ul>
<h2 id=participation-in-workshops-or-competitions><img style="width:1.5em" src="imgs/section-scientific-events.svg"> Participation in Workshops or Competitions</h2>
<ul>
<li>2022: <b>Bosch for Mobility:</b> My students won Best New Participating Team in an autonomous driving competition promoted by Bosch Romania. <a href="https://noticias.up.pt/estudantes-da-u-porto-brilham-em-concurso-de-conducao-autonoma-da-bosch/"><img width="20px" src="imgs/link.svg"></a></li>
<li>2019: <b>DSPT Day:</b> lightning talk (a two-day machine learning event for a public audience)</li>
<li>2018: <b>Junior University:</b> organized with my supervisor (Prof. Jaime Cardoso) an activity for the Junior University entitled "Escondidos nos Dados". The Junior University is an opportunity that the University of Porto gives children to get to know and do activities at the university. This activity took place for a month, with classes with different children every day, from the 8th and 9th grades. The website archives is not working, but this link describes an award I received from INESC TEC for organizing these activities, among others. <a href="http://bip-archive.inesctec.pt/196/fora-de-serie.html"><img width="20px" src="imgs/link.svg"></a></li>
<li>2018: <b>VISUM:</b> helped prepare a computational framework in which students submitted processes and generated Kaggle-style leaderboards (using Google Cloud) for the competitions that take place during the VISUM computer vision summer school, a framework that continues to be used today.</li>
<li>2017: organized some workshops, especially at INESC TEC, namely <b>Learning from Data</b>, which was part of the CTM Open Day. (The CTM is the INESC TEC unit that I was part of.) <a href="https://opendayctm.inesctec.pt/2017/index.php/learning-from-data/"><img width="20px" src="imgs/link.svg"></a></li>
<li>2017: Free public workshop, in collaboration with João Machado, in the <b>Python Meetup</b> entitled <i>NumPy and Scikit-Learn</i>. The Python Meetup was a monthly meeting about Python in Porto, which has since been discontinued. <a href="https://youtu.be/klr1z1EJ1yY"><img width="20px" src="imgs/link.svg"></a></li>
</ul>
<h2 id=impact-and-citations><img style="width:1.5em" src="imgs/section-scientific-impact.svg"> Impact and Citations</h2>
<ul>
<li>Google Scholar (may/2023): 171 citations, 7 h-index <a href="https://scholar.google.com/citations?user=pSFY_gQAAAAJ"><img width="20px" src="imgs/link.svg"></a></li>
<li>Web of Science (may/2023): 73 citations, 4 h-index <a href="https://www.webofscience.com/wos/author/record/IQV-2746-2023"><img width="20px" src="imgs/link.svg"></a></li>
<li>Scopus (may/2023): 111 citations, 5 h-index <a href="https://www.scopus.com/authid/detail.uri?authorId=57192670388"><img width="20px" src="imgs/link.svg"></a></li>
<li>Best oral paper: 2021 RECPAD conference <a href="https://noticias.up.pt/investigadores-da-u-porto-dominam-premios-do-recpad-2021/"><img width="20px" src="imgs/link.svg"></a></li>
</ul>
<h4 id=conference-publications><img style="width:1.5em" src="imgs/section-publications.svg"> Conference Publications</h4>
<p>My favorite publications are in <span class="hl">highlight</span>, including a summary of the main contributions for those papers.</p>
<ol>
<li><b>Ricardo P. M. Cruz</b>, ASM Shihavuddin, Hasan Maruf, Jaime S. Cardoso. Active Supervision: Human in the Loop. <b>[ACCEPTED]</b> <i>Springer Iberoamerican Congress, CIARP 2023</i> <b>CORE RANK=C</b></li>
<li>Diana Teixeira Silva, <b>Ricardo P. M. Cruz</b>. Condition Invariance for Autonomous Driving by Adversarial Learning. <b>[ACCEPTED]</b> <i>Springer Iberoamerican Congress, CIARP 2023</i> <b>CORE RANK=C</b></li>
<li>Filipe Campos, Francisco Gonçalves Cerqueira, <b>Ricardo P. M. Cruz</b>, Jaime S. Cardoso. YOLOMM &ndash; You Only Look Once for Multi-modal Multi-tasking. <b>[ACCEPTED]</b> <i>Springer Iberoamerican Congress, CIARP 2023</i> <b>CORE RANK=C</b></li>
<li><span class="hl">P. S. Silva, <b>R. Cruz</b>, ASM Shihavuddin, T. Gonçalves (2023). Interpretability-Guided Human Feedback During Neural Network Training. <i>Springer Iberian Conference on Pattern Recognition and Image Analysis (Ibpria)</i></span> <a href="https://link.springer.com/chapter/10.1007/978-3-031-36616-1_22"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=C</b></li>
<ul class="small">
<li>In this article, which resulted from a master's thesis supervision, the objective was that the human could provide feedback during the optimization process. Usually, the role of the human is only to make notes on the data, and then the optimization process is automatic. When the model falls below expectations it is necessary to collect more data and re-annotate them. In this work, interpretability tools are used to identify the image regions that are influencing the model result the most, then the user is asked whether any of these regions should not be responsible for the decision. This user feedback is then integrated into the loss to penalize the model if it continues to focus on these regions. A small improvement of the approach was noted in regimes where there is little data.</li>
</ul>
<li>D. Silva, <b>R. Cruz</b>, T. Gonçalves, D. Carneiro (2023). Two-stage Semantic Segmentation in Neural Networks. <i>Proceedings of the Fifteenth International Conference on Machine Vision (ICMV)</i> <a href="https://tiagofilipesousagoncalves.github.io/publications/pdf/dianartsilva2022icmv.pdf"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=C</b></li>
<li><span class="hl"><b>R. Cruz</b>, R. Prates, E. Filho, J. Costa, J. Cardoso (2021). Background Invariance by Adversarial Learning. <i>IEEE 25th International Conference on Pattern Recognition (ICPR)</i></span> <a href="https://ieeexplore.ieee.org/document/9413004"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=B</b></li>
<ul class="small">
<li>Convolutional neural networks (CNNs) are vulnerable to changes in the background of the image: for example, training a CNN with the popular MNIST digit recognition dataset we easily achieved an accuracy of close to 100\%; however, if we replace the background (which is white) with stripes, the accuracy drops to 40\%, and if we replace it with noise then the accuracy can drop to 10\%. The proposed method consists of three neural networks trained together (end-to-end): (1) the classification CNN $f$ that we want to make more robust; (2) a CNN $s$ that does a coarse segmentation of the object; (3) a CNN $g$ that generates possible backgrounds for the image. During inference, only the $f$ model is used, $y=f(x)$, where $x$ is the input image. The models $s$ and $g$ are only used during the optimization process, $y=f(g(\epsilon)+x\otimes s(x))$, where $\epsilon$ is white noise and $\otimes$ is the element-by-element product. The models are optimized in an adversarial way: $\min_{f,s} Loss(y)$ and the model $g$ tries to generate funds that make the job as difficult as possible, $\max_g Loss(y)$. To prevent the $g$ template from generating objects from other classes as background, the $g$ template only generates independent subregions that are then concatenated. The optimization is inspired by other adversarial neural networks, such as GANs, although it is not a GAN as there is no discriminator, nor are there examples of realistic backgrounds. The case study explores a fault detection dataset in electrical insulators, collected by a co-author from UFBA (Brazil). Here the objective was to be able to train with insulators, whose photographs were collected in a controlled environment in a laboratory, and it was intended that the model was robust enough to be able to detect defects in conditions later in the real world, in which the background of objects is very different. of the laboratory.</li>
</ul>
<li><b>R. Cruz</b>, J. Costa, J. Cardoso (2019). Automatic Augmentation by Hill Climbing. <i>Springer 28th International Conference on Artificial Neural Networks (ICANN)</i> <a href="https://link.springer.com/chapter/10.1007/978-3-030-30484-3_10"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=C</b></li>
<li><span class="hl"><b>R. Cruz</b>, J. Costa, J. Cardoso (2019). Averse Deep Semantic Segmentation. <i>IEEE 41st Engineering in Medicine and Biology Conference (EMBC)</i></span> <a href="https://ieeexplore.ieee.org/abstract/document/8857385"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=C</b></li>
<ul class="small">
<li>In binary tasks we can consider two types of errors: type I errors (false negatives) and type II errors (false positives). There is an inherent trade-off between these two types of errors: we can reduce the false positive rate (FPR) by increasing the false negative rate (FNR) and vice versa. The common way to define this commitment is through a cost matrix: we are defining that we tolerate $\alpha$ errors of one type of error as $\beta$ errors of the other type, $\min \alpha\text{FPR} +\beta\text{FNR}$. However, this way of establishing relative errors may not be the most natural. It might be more natural for the definition to be absolute: we tolerate at most up to $X$ of one type of error, minimizing errors of the other type, $\min \text{FPR}, \text{subject to } \text{FNR} \ leq X$. This way of defining an absolute error on one of the error types forces us to rethink the optimization process. In this work, approaches such as the use of thresholds, adding a term to the loss and optimizing with two alternating objectives were proposed.</li>
</ul>
<li><b>R. Cruz</b>, M. Silveira, J. Cardoso (2018). A Class Imbalance Ordinal Method for Alzheimer's Disease Classification. <i>IEEE International Workshop on Pattern Recognition in Neuroimaging (PRNI)</i> <a href="https://ieeexplore.ieee.org/abstract/document/8423960/"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=n/a</b></li>
<li><span class="hl">K. Fernandes, <b>R. Cruz</b>, J. Cardoso (2018). Deep image segmentation by quality inference. <i>IEEE International Joint Conference on Neural Networks (IJCNN)</i></span> <a href="https://ieeexplore.ieee.org/abstract/document/8489696/"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=B</b></li>
<ul class="small">
<li>Traditionally, neural networks model a function $f$, such that $y=f(x)$, where $x$ is the input and $y$ the output of the neural network. Inference in neural networks is therefore done in just one step, unlike other classic models in which inference is iterative, which allows improving existing solutions and greater transparency in processing. The proposal is that of a neural network that produces the quality of a pair (input, output): $q=f(x,y)$, where q is the function that models the quality produced by the model. In this way, the output $y$ can then be iteratively and gradually improved through a gradient ascent process: $y_{t+1}=y_t+\frac{\partial f(x,y_t)}{\partial y_t }$, for each iteration $t$. This approach was applied to semantic segmentation, with $y_0$ being a completely black segmentation.</li>
</ul>
<li><b>R. Cruz</b>, K. Fernandes, J. Costa, J. Cardoso (2017). Constraining type II error: building intentionally biased classifiers. <i>Springer International Work-conference on Artificial Neural Networks (IWANN)</i> <a href="https://link.springer.com/chapter/10.1007/978-3-319-59147-6_47"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=n/a</b></li>
<li>M. Pérez-Ortiz, K. Fernandes, <b>R. Cruz</b>, J. Cardoso (2017). Fine-to-coarse ranking in ordinal and imbalanced domains: an application to liver transplantation. <i>Springer International Work-conference on Artificial Neural Networks (IWANN)</i> <a href="https://link.springer.com/chapter/10.1007/978-3-319-59147-6_45"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=n/a</b></li>
<li><b>R. Cruz</b>, K. Fernandes, J. Costa, M. Pérez-Ortiz, J. Cardoso (2017). Combining ranking with traditional methods for ordinal class imbalance. <i>Springer International Work-conference on Artificial Neural Networks (IWANN)</i> <a href="https://link.springer.com/chapter/10.1007/978-3-319-59147-6_46"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=n/a</b></li>
<li>"<b>R. Cruz</b>, K. Fernandes, J. Costa, M. Pérez-Ortiz, J. Cardoso (2017). Ordinal class imbalance with ranking. <i>Springer Iberian conference on pattern recognition and image analysis (Ibpria)</i> <a href="https://link.springer.com/chapter/10.1007/978-3-319-58838-4_1"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=C</b></li>
<li><span class="hl"><b>R. Cruz</b>, K. Fernandes, J. Costa, J. Cardoso (2016). Tackling class imbalance with ranking. <i>IEEE International Joint Conference on Neural Networks (IJCNN)</i></span> <a href="http://ieeexplore.ieee.org/abstract/document/7727469/"><img width="20px" src="imgs/link.svg"></a> <b>CORE RANK=B</b></li>
<ul class="small">
<li>In automatic classification tasks, it is common to have a disproportion between the number of copies of each class, something known as "class imbalance." In the binary case, the minority class contributes little to the decision frontier because the optimization is done considering each point in isolation. Conventional solutions consist of: resampling the data to balance them (pre-processing) or assigning different weights to each class (optimization) or fine-tuning the decision frontier threshold (post-processing). The proposal consists of using the same optimization process that is used in pairwise sorting methods in the ``learning to rank'' literature. These models minimize losses using pairs of observations, $Loss(f(x1), f(x2))$. In our adaptation for binary classification, the optimization is done by comparing an observation of a class with an observation of another class, causing the "class imbalance" to disappear automatically in the binary case, since the loss always takes into account observations of both classes.</li>
</ul>
</ol>
<h4 id=journal-publications><img style="width:1.5em" src="imgs/section-publications.svg"> Journal Publications</h4>
<p>The SJR rank is from <a href="https://www.scimagojr.com/">SJR Scimago</a>, quantiles from 2022.</p>
<ol>
<li><b>R. Cruz</b>, D. Silva, T. Gonçalves, D. Carneiro, J. Cardoso (2023). Two-Stage Framework for Faster Semantic Segmentation. <i>MDPI Sensors</i> <a href="https://www.mdpi.com/1424-8220/23/6/3092"><img width="20px" src="imgs/link.svg"></a> <b>Q2 (eletrical engineering)</b></li>
<li>T. Albuquerque, L. Rosado, <b>R. Cruz</b>, M. Vasconcelos, T. Oliveira, J. Cardoso (2023). Rethinking Low-Cost Microscopy Workflow: Image Enhancement using Deep Based Extended Depth of Field Methods. <i>Elsevier Intelligent Systems with Applications</i> <a href="https://doi.org/10.1016/j.iswa.2022.200170"><img width="20px" src="imgs/link.svg"></a> <b>Q1 (computer vision and pattern recognition)</b></li>
<li>T. Albuquerque, <b>R. Cruz</b>, J. Cardoso (2022). Quasi-Unimodal Distributions for Ordinal Classification. <i>MDPI Mathematics</i> <a href="https://www.mdpi.com/2227-7390/10/6/980"><img width="20px" src="imgs/link.svg"></a> <b>Q2 (computer science)</b></li>
<li>T. Albuquerque, <b>R. Cruz</b>, J. Cardoso (2021). Ordinal Losses for Classification of Cervical Cancer Risk. <i>PeerJ Computer Science</i> <a href="https://peerj.com/articles/cs-457/"><img width="20px" src="imgs/link.svg"></a> <b>Q2 (computer science)</b></li>
<li>R. Prates, <b>R. Cruz</b>, A. Marotta, R. Ramos, E. Filho, J. Cardoso (2019). Insulator visual non-conformity detection in overhead power distribution lines using deep learning. <i>Elsevier Journal Computers &amp; Electrical Engineering</i> <a href="https://www.sciencedirect.com/science/article/pii/S004579061930967X?dgcid=coauthor"><img width="20px" src="imgs/link.svg"></a> <b>Q1 (computer science)</b></li>
<li><b>R. Cruz</b>, K. Fernandes, J. Costa, M. Pérez Ortiz, J. Cardoso (2018). Binary ranking for ordinal class imbalance. <i>Springer Journal Pattern Analysis and Applications</i> <a href="https://link.springer.com/epdf/10.1007/s10044-018-0705-4?author_access_token=p2L5jwabAzmA-hENM_mugfe4RwlQNchNByi7wbcMAY42mOH72RPQeb098_tyy79R09eJLVa1A5i0Fl8_sgW1ks0WseTTuEtHZyi1eB8zBX3Z7vgZBxHJZ3x26EzyODMrDn4oUkmT-tVcZK4oD3u4vQ%3D%3D"><img width="20px" src="imgs/link.svg"></a> <b>Q2 (computer vision and pattern recognition)</b></li>
</ol>
<h2 id=collaborations-as-editor-or-evaluator><img style="width:1.5em" src="imgs/section-scientific-impact.svg"> Collaborations as Editor or Evaluator</h2>
<div class="columns">
<div class="item"><div class="left">2021</div><div class="right"><b>A3ES:</b> student member (as a PhD student) of three evaluation committees: a master's course and two doctorates.</div></div>
<div class="item"><div class="left">2020</div><div class="right"><b>iMIMIC/MIL3ID/LABELS 2020 workshop proceedings (MICCAI 2020):</b> helped organize the iMIMIC 2020 workshop (part of MICCAI 2020) and was later co-editor of the publication of the joint proceedings of three MICCAI 2020 workshops.</div></div>
</div>
<h2 id=jury-participation><img style="width:1.5em" src="imgs/section-jury-participation.svg"> Jury Participation</h2>
<div class="columns">
<div class="item"><div class="left">2023</div><div class="right">Ricardo Ribeiro: <i>AI-based models to predict the Traumatic Brain Injury outcome</i> (FCUP, External Examiner)</div></div>
<div class="item"><div class="left">2022</div><div class="right">Mafalda Oliveira: <i>Neuroblastoma Cancer Radiogenomics</i> (FEUP, External Examiner)</div></div>
<div class="item"><div class="left">2022</div><div class="right">João Pedro Fonseca: <i>AI-Based Models to Predict The Traumatic Brain Injury Outcome</i> (FEUP, External Examiner)</div></div>
<div class="item"><div class="left">2022</div><div class="right">Ana Maria Sousa: <i>Learning to write medical reports from EEG data</i> (FEUP, Chairman)</div></div>
<div class="item"><div class="left">2022</div><div class="right">Bruno Nascimento: <i>Detection and classification of small impacts on vehicles based on deep learning algorithms</i> (U. Minho, External Examiner)</div></div>
<div class="item"><div class="left">2021</div><div class="right">Artur Ferreira: <i>3D Lung Computed Tomography Synthesis using Generative Adversarial Networks</i> (FCUP, External Examiner)</div></div>
<div class="item"><div class="left">2021</div><div class="right">Vítor Figueiredo: <i>Feasibility of using autoencoders for learning car interior background models</i> (U. Minho, External Examiner)</div></div>
</div>
<h2 id=m.sc.-supervisions><img style="width:1.5em" src="imgs/section-supervisions.svg"> M.Sc. Supervisions</h2>
<div class="columns">
<div class="item"><div class="left">on-going</div><div class="right">Francisco Gonçalves Cerqueira: <i>Comparative Study on Self-Supervision Methods for Autonomous Driving</i> (FEUP)</div></div>
<div class="item"><div class="left">on-going</div><div class="right">Diana Teixeira Silva: <i>Quantifying How Deep Implicit Representations Promote Label Efficiency</i> (FEUP)</div></div>
<div class="item"><div class="left">2023</div><div class="right">Alankrita Asthana: <i>Iterative Inference for Point-Clouds</i> (TUM, Munich)</div></div>
<div class="item"><div class="left">2023</div><div class="right">Rafael Cristino (with J. Cardoso): <i>Introducing Domain Knowledge to Scene Parsing in Autonomous Driving</i> (FEUP)</div></div>
<div class="item"><div class="left">2023</div><div class="right">José Guerra (with L. Teixeira): <i>Academic Internship in Out of Distribution Detection – Autonomous Driving</i> (Internship at Bosch Car Multimedia) (FEUP)</div></div>
<div class="item"><div class="left">2022</div><div class="right">Pedro Silva (with T. Gonçalves): <i>Human Feedback during Neural Networks Training</i> (FEUP) <a href="https://sigarra.up.pt/feup/pt/pub_geral.pub_view?pi_pub_base_id=570677"><img width="20px" src="imgs/link.svg"></a></div></div>
<div class="item"><div class="left">2022</div><div class="right">João Silva: <i>Environment Detection for Railway Applications based on Automotive Technology</i> (Internship at Continental) (FEUP) <a href="https://sigarra.up.pt/feup/pt/pub_geral.pub_view?pi_pub_base_id=570251"><img width="20px" src="imgs/link.svg"></a></div></div>
<div class="item"><div class="left">2022</div><div class="right">Ana Bezerra (with J. Costa): <i>Phishing Detection with a Machine Learning Net</i> (Internship at E-goi) (FCUP) <a href="https://repositorio-aberto.up.pt/handle/10216/147350"><img width="20px" src="imgs/link.svg"></a></div></div>
</div>
<h2 id=b.sc.-projects-supervisions><img style="width:1.5em" src="imgs/section-supervisions.svg"> B.Sc. Projects Supervisions</h2>
<div class="columns">
<div class="item"><div class="left">2023</div><div class="right">Diana Silva: <i>Condition Invariance for Autonomous Driving by Adversarial Learning</i></div></div>
<div class="item"><div class="left">2022</div><div class="right">Diana Silva (with T. Gonçalves): <i>Semantic Segmentation in Neural Networks using Iterative Visual Attention</i></div></div>
<div class="item"><div class="left">2022</div><div class="right">Filipe Campos, Francisco Cerqueira, Vasco Alves: <i>Mobile App using Object Detection for Car Driving</i></div></div>
<div class="item"><div class="left">2022</div><div class="right">Bruno Gomes, Rafael Camelo: Internship at ANO</div></div>
</div>
<center class="bigskip small">Last update: 2023-09-21</center>
</body>
</html>
